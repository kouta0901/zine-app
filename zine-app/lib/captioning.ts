// Browser-compatible Vertex AI Gemini Image Captioning Service  
export class ImageCaptioningService {
  private isServerSide: boolean;
  private vertex: any = null;
  private model: any = null;

  constructor() {
    this.isServerSide = typeof window === 'undefined';
    
    // Only initialize on server side
    if (this.isServerSide) {
      this.initializeVertex();
    } else {
      console.log('üîß Captioning Service running in browser mode (mock implementation)');
    }
  }

  private async initializeVertex() {
    const projectId = process.env.GCP_PROJECT || process.env.GOOGLE_CLOUD_PROJECT;
    const location = process.env.VERTEX_AI_LOCATION || "us-central1";

    if (!projectId) {
      console.warn("Vertex AI environment variables not configured. Image captioning will be disabled.");
      return;
    }

    try {
      const { VertexAI } = require("@google-cloud/vertexai");
      this.vertex = new VertexAI({ 
        project: projectId, 
        location: location 
      });
      
      // Use Gemini 2.5 Flash for speed and cost efficiency
      this.model = this.vertex.getGenerativeModel({ 
        model: "gemini-2.5-flash" 
      });
    } catch (error) {
      console.error("Failed to initialize Vertex AI:", error);
    }
  }

  /**
   * Generate detailed caption for ZINE image content
   * Optimized for narrative and visual storytelling
   */
  async generateImageCaption(
    base64Image: string, 
    hint: string = "",
    style: CaptionStyle = "narrative"
  ): Promise<CaptionResult> {
    if (!this.model) {
      return {
        caption: "",
        confidence: 0,
        error: "Vertex AI not configured"
      };
    }

    try {
      const prompt = this.buildCaptionPrompt(style, hint);
      
      const response = await this.model.generateContent({
        contents: [{
          role: "user",
          parts: [
            { text: prompt },
            { 
              inlineData: { 
                mimeType: "image/png", 
                data: base64Image 
              } 
            }
          ]
        }]
      });

      const caption = response.response?.candidates?.[0]?.content?.parts?.map((p: any) => p.text).join("") ?? "";
      
      return {
        caption,
        confidence: this.calculateConfidenceFromResponse(response),
        style,
        timestamp: new Date().toISOString()
      };

    } catch (error) {
      console.error("Image captioning failed:", error);
      return {
        caption: "",
        confidence: 0,
        error: `Captioning failed: ${error.message}`,
        style
      };
    }
  }

  /**
   * Answer specific questions about image content
   * Useful for extracting specific details for story generation
   */
  async analyzeImageWithQuestions(
    base64Image: string,
    questions: string[],
    context: string = ""
  ): Promise<ImageAnalysisResult> {
    if (!this.model) {
      return {
        answers: {},
        summary: "",
        confidence: 0,
        error: "Vertex AI not configured"
      };
    }

    try {
      const prompt = this.buildAnalysisPrompt(questions, context);
      
      const response = await this.model.generateContent({
        contents: [{
          role: "user",
          parts: [
            { text: prompt },
            { 
              inlineData: { 
                mimeType: "image/png", 
                data: base64Image 
              } 
            }
          ]
        }]
      });

      const responseText = response.response?.candidates?.[0]?.content?.parts?.map((p: any) => p.text).join("") ?? "";
      const answers = this.parseQAResponse(responseText, questions);
      
      return {
        answers,
        summary: responseText,
        confidence: this.calculateConfidenceFromResponse(response),
        timestamp: new Date().toISOString()
      };

    } catch (error) {
      console.error("Image analysis failed:", error);
      return {
        answers: {},
        summary: "",
        confidence: 0,
        error: `Analysis failed: ${error.message}`
      };
    }
  }

  /**
   * Enhanced caption generation for ZINE-to-novel conversion
   * Combines captioning with contextual hints from nearby text
   */
  async generateEnhancedCaption(
    base64Image: string,
    nearbyText: string = "",
    pageContext: string = "",
    imageIndex: number = 0
  ): Promise<EnhancedCaptionResult> {
    
    // Browser mode - return mock data for testing
    if (!this.isServerSide || !this.model) {
      console.log('üîß Captioning: Using mock data (browser mode or not configured)');
      
      // Mock enhanced caption for general content example
      return {
        caption: `„Éö„Éº„Ç∏${imageIndex + 1}„Å´„ÅØÂç∞Ë±°ÁöÑ„Å™‰∫∫Áâ©„ÇÑÁâ©‰Ωì„ÅåÊèè„Åã„Çå„Å¶„ÅÑ„Çã„ÄÇÊòé„Çã„ÅÑËâ≤ÂΩ©„ÅßË°®Áèæ„Åï„Çå„Åü‰∏ªË¶Å„Å™Ë¶ÅÁ¥†„Åå„ÄÅÁîªÈù¢„ÅÆ‰∏≠Â§Æ„Å´ÈÖçÁΩÆ„Åï„Çå„Å¶„ÅÑ„Çã„ÄÇËÉåÊôØ„Å´„ÅØËá™ÁÑ∂„Å™Áí∞Â¢É„ÇÑÂª∫Áâ©„ÅåË¶ã„Åà„ÄÅÂÖ®‰ΩìÁöÑ„Å´Ë™øÂíå„ÅÆÂèñ„Çå„ÅüÊßãÂõ≥„Å®„Å™„Å£„Å¶„ÅÑ„Çã„ÄÇÁîªÂÉè„ÅÆ‰∏ÄÈÉ®„Å´„ÅØ„ÉÜ„Ç≠„Çπ„Éà„ÇÑË™¨ÊòéÊñá„ÅåÂê´„Åæ„Çå„Å¶„Åä„Çä„ÄÅÂÜÖÂÆπ„ÅÆÁêÜËß£„ÇíÂä©„Åë„Å¶„ÅÑ„Çã„ÄÇ`,
        analysis: {
          question_1: "‰∏ªË¶Å„Å™Ë¶ñË¶öË¶ÅÁ¥†„ÅØ‰∏≠Â§Æ„Å´ÈÖçÁΩÆ„Åï„Çå„Åü‰∫∫Áâ©„ÇÑÁâ©‰Ωì„Åß„ÄÅÊòéÁ¢∫„Å´Ë≠òÂà•„Åß„Åç„ÇãÂΩ¢„ÅßÊèè„Åã„Çå„Å¶„ÅÑ„Åæ„Åô",
          question_2: "ÁôªÂ†¥„Åô„ÇãË¶ÅÁ¥†„ÅØËá™ÁÑ∂„ÅßË°®ÊÉÖË±ä„Åã„Å™Áä∂ÊÖã„ÇíÁ§∫„Åó„Å¶„Åä„Çä„ÄÅÁâ©Ë™ûÊÄß„ÇíÊÑü„Åò„Åï„Åõ„Åæ„Åô",
          question_3: "ÁîªÂÉèÂÖ®‰Ωì„Å´Ê∏©„Åã„Åø„ÅÆ„ÅÇ„ÇãÈõ∞Âõ≤Ê∞ó„ÅåÊºÇ„Å£„Å¶„Åä„Çä„ÄÅË¶™„Åó„Åø„ÇÑ„Åô„ÅÑ‰∏ñÁïåË¶≥„ÇíË°®Áèæ„Åó„Å¶„ÅÑ„Åæ„Åô",
          question_4: "ËÉåÊôØ„ÅØÈÅ©Â∫¶„Å´Ë©≥Á¥∞„Åß„ÄÅ‰∏ªË¶ÅÁ¥†„ÇíÂºï„ÅçÁ´ã„Å¶„ÇãÂΩπÂâ≤„ÇíÊûú„Åü„Åó„Å¶„ÅÑ„Åæ„Åô",
          question_5: "ÁîªÂÉèÂÜÖ„Å´„ÅØ„Çø„Ç§„Éà„É´„ÇÑË™¨ÊòéÊñá„Å™„Å©„ÅÆ„ÉÜ„Ç≠„Çπ„ÉàË¶ÅÁ¥†„ÅåÈÅ©Âàá„Å´ÈÖçÁΩÆ„Åï„Çå„Å¶„ÅÑ„Åæ„Åô",
          question_6: "„Åì„ÅÆÁîªÂÉè„ÅØÁâ©Ë™û„ÅÆÈáçË¶Å„Å™Â†¥Èù¢„ÇíË°®Áèæ„Åó„Å¶„Åä„Çä„ÄÅË™≠ËÄÖ„ÅÆËààÂë≥„ÇíÂºï„ÅèÂÜÖÂÆπ„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô"
        },
        visualElements: ["‰∫∫Áâ©", "ËÉåÊôØ", "„ÉÜ„Ç≠„Çπ„Éà", "Ëâ≤ÂΩ©", "ÊßãÂõ≥"],
        emotionalTone: "positive",
        storyContext: `ËààÂë≥Ê∑±„ÅÑÂ†¥Èù¢„ÅÆÊèèÂÜô | Èñ¢ÈÄ£„ÉÜ„Ç≠„Çπ„Éà: ${nearbyText} | „Éö„Éº„Ç∏ÊñáËÑà: ${pageContext}`,
        confidence: 0.89,
        imageIndex,
        error: undefined
      };
    }
    const questions = [
      "„Åì„ÅÆÁîªÂÉè„ÅÆ‰∏ªË¶Å„Å™Ë¶ñË¶öË¶ÅÁ¥†„ÅØ‰Ωï„Åß„Åô„ÅãÔºü",
      "ÁîªÂÉè„Å´Êèè„Åã„Çå„Å¶„ÅÑ„Çã‰∫∫Áâ©„ÇÑÁâ©‰Ωì„ÅÆË°®ÊÉÖ„ÇÑÁä∂ÊÖã„ÅØÔºü",
      "ÁîªÂÉè„ÅÆÈõ∞Âõ≤Ê∞ó„ÇÑÊÑüÊÉÖÁöÑ„Å™„Éà„Éº„É≥„ÅØÔºü",
      "ËÉåÊôØ„ÇÑË®≠ÂÆö„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
      "ÁîªÂÉèÂÜÖ„Å´ÊñáÂ≠ó„ÇÑ„ÉÜ„Ç≠„Çπ„Éà„ÅåË¶ã„Åà„Åæ„Åô„ÅãÔºü",
      "„Åì„ÅÆÁîªÂÉè„ÅåÁâ©Ë™û„ÅÆ‰∏≠„Åß„Å©„ÅÆ„Çà„ÅÜ„Å™Â†¥Èù¢„ÇíË°®„Åó„Å¶„ÅÑ„Çã„Å®ÊÄù„ÅÑ„Åæ„Åô„ÅãÔºü"
    ];

    const [caption, analysis] = await Promise.all([
      this.generateImageCaption(
        base64Image, 
        `Âë®Ëæ∫„ÉÜ„Ç≠„Çπ„Éà: ${nearbyText}\n„Éö„Éº„Ç∏ÊñáËÑà: ${pageContext}`,
        "detailed"
      ),
      this.analyzeImageWithQuestions(base64Image, questions, pageContext)
    ]);

    return {
      caption: caption.caption,
      analysis: analysis.answers,
      visualElements: this.extractVisualElements(analysis.summary),
      emotionalTone: this.extractEmotionalTone(analysis.summary),
      storyContext: this.generateStoryContext(caption.caption, nearbyText, pageContext),
      confidence: (caption.confidence + analysis.confidence) / 2,
      error: caption.error || analysis.error,
      imageIndex
    };
  }

  /**
   * Build caption generation prompt based on style
   */
  private buildCaptionPrompt(style: CaptionStyle, hint: string): string {
    const basePrompt = "ÁîªÂÉè„ÅÆÂÜÖÂÆπ„ÇíË©≥„Åó„ÅèÂàÜÊûê„Åó„ÄÅ‰ª•‰∏ã„ÅÆË¶Å‰ª∂„Å´Âæì„Å£„Å¶Ë™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö";
    
    const stylePrompts = {
      narrative: `
${basePrompt}
- Â∞èË™¨„ÅÆÂú∞„ÅÆÊñá„Å®„Åó„Å¶‰Ωø„Åà„ÇãÊÉÖÊôØÊèèÂÜô„ÅßË®òËø∞
- 200Â≠ó‰ª•ÂÜÖ„ÅßÁ∞°ÊΩî„Å´
- Ë¶ñË¶öÁöÑ„Å™Ë©≥Á¥∞„Å®Èõ∞Âõ≤Ê∞ó„ÇíÈáçË¶ñ
- Ë™≠ËÄÖ„ÅÆÊÉ≥ÂÉèÂäõ„ÇíÊéª„ÅçÁ´ã„Å¶„ÇãË°®Áèæ„Çí‰ΩøÁî®`,

      detailed: `
${basePrompt}
- ÁîªÂÉè„ÅÆÂÖ®„Å¶„ÅÆË¶ñË¶öË¶ÅÁ¥†„ÇíË©≥Á¥∞„Å´Ë®òËø∞
- ‰∫∫Áâ©„ÄÅÁâ©‰Ωì„ÄÅËÉåÊôØ„ÄÅËâ≤ÂΩ©„ÄÅÊßãÂõ≥„ÇíÂê´„ÇÄ
- 300Â≠ó‰ª•ÂÜÖ„Åß‰ΩìÁ≥ªÁöÑ„Å´
- Áâ©Ë™ûÁîüÊàê„Å´ÂøÖË¶Å„Å™ÊÉÖÂ†±„ÇíÂÑ™ÂÖà`,

      technical: `
${basePrompt}
- ÁîªÂÉè„ÅÆÊäÄË°ìÁöÑ„ÉªÂÆ¢Ë¶≥ÁöÑ„Å™Ë®òËø∞
- Ë¶ÅÁ¥†„ÅÆÈÖçÁΩÆ„ÄÅ„Çµ„Ç§„Ç∫„ÄÅÈñ¢‰øÇÊÄß„ÇíÊòéÁ¢∫„Å´
- 150Â≠ó‰ª•ÂÜÖ„ÅßÊ≠£Á¢∫„Å´
- Ê∏¨ÂÆöÂèØËÉΩ„Å™ÁâπÂæ¥„ÇíÈáçË¶ñ`,

      emotional: `
${basePrompt}
- ÁîªÂÉè„ÅåË°®Áèæ„Åó„Å¶„ÅÑ„ÇãÊÑüÊÉÖ„ÇÑÈõ∞Âõ≤Ê∞ó„ÇíÈáçË¶ñ
- Ë¶ã„Çã‰∫∫„ÅÆÊÑüÊÉÖ„Å´Ë®¥„Åà„ÇãË®òËø∞
- 180Â≠ó‰ª•ÂÜÖ„ÅßÊÑüÊÉÖË±ä„Åã„Å´
- Áâ©Ë™û„ÅÆÊÑüÊÉÖÁöÑ„Å™ÊñáËÑà„ÇíÂº∑Âåñ`
    };

    let prompt = stylePrompts[style];
    
    if (hint) {
      prompt += `\n\nË£úÂä©ÊÉÖÂ†±: ${hint}`;
    }

    return prompt;
  }

  /**
   * Build image analysis prompt with questions
   */
  private buildAnalysisPrompt(questions: string[], context: string): string {
    let prompt = `ÁîªÂÉè„ÇíË©≥„Åó„ÅèÂàÜÊûê„Åó„ÄÅ‰ª•‰∏ã„ÅÆË≥™Âïè„Å´Êó•Êú¨Ë™û„ÅßÁ≠î„Åà„Å¶„Åè„Å†„Åï„ÅÑÔºö\n\n`;
    
    questions.forEach((q, i) => {
      prompt += `${i + 1}. ${q}\n`;
    });

    if (context) {
      prompt += `\nÊñáËÑàÊÉÖÂ†±: ${context}`;
    }

    prompt += `\n\nÂêÑË≥™Âïè„Å´ÂØæ„Åó„Å¶ÊòéÁ¢∫„ÅßÂÖ∑‰ΩìÁöÑ„Å™ÂõûÁ≠î„ÇíÊèê‰æõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ`;

    return prompt;
  }

  /**
   * Parse question-answer response
   */
  private parseQAResponse(responseText: string, questions: string[]): Record<string, string> {
    const answers: Record<string, string> = {};
    
    // Simple parsing - in production, might want more sophisticated NLP
    const lines = responseText.split('\n').filter(line => line.trim());
    
    questions.forEach((question, index) => {
      const questionKey = `question_${index + 1}`;
      const answerLine = lines.find(line => 
        line.includes(`${index + 1}.`) || line.includes(`${index + 1}:`)
      );
      
      if (answerLine) {
        // Extract answer after number and punctuation
        const answer = answerLine.replace(/^\d+[.:]\s*/, '').trim();
        answers[questionKey] = answer;
      }
    });

    // If parsing fails, store the full response
    if (Object.keys(answers).length === 0) {
      answers['full_response'] = responseText;
    }

    return answers;
  }

  /**
   * Extract visual elements from analysis
   */
  private extractVisualElements(summary: string): string[] {
    const elements: string[] = [];
    const keywords = [
      '‰∫∫Áâ©', 'È°î', 'Ë°®ÊÉÖ', 'Êâã', '‰Ωì',
      'Âª∫Áâ©', 'È¢®ÊôØ', 'Á©∫', 'Èõ≤', 'Â±±', 'Êµ∑',
      'Ëâ≤', 'ÂÖâ', 'ÂΩ±', 'ËÉåÊôØ',
      'ÊñáÂ≠ó', '„ÉÜ„Ç≠„Çπ„Éà', 'ÁúãÊùø', '„Ç´„Éº„Éâ'
    ];

    keywords.forEach(keyword => {
      if (summary.includes(keyword)) {
        elements.push(keyword);
      }
    });

    return elements;
  }

  /**
   * Extract emotional tone from analysis
   */
  private extractEmotionalTone(summary: string): string {
    const emotions = [
      { keywords: ['Êòé„Çã„ÅÑ', 'Ê•Ω„Åó„ÅÑ', 'Âπ∏„Åõ', 'Âñú„Å≥'], tone: 'positive' },
      { keywords: ['Êöó„ÅÑ', 'ÊÇ≤„Åó„ÅÑ', 'ÊÜÇÈ¨±', 'ËêΩ„Å°Ëæº„Åø'], tone: 'melancholic' },
      { keywords: ['Á∑äÂºµ', '‰∏çÂÆâ', 'ÊÅêÊÄñ', 'ÂøÉÈÖç'], tone: 'tense' },
      { keywords: ['Âπ≥Âíå', 'Èùô„Åã', 'Á©è„ÇÑ„Åã', 'ÂÆâ„Çâ„Åã'], tone: 'peaceful' },
      { keywords: ['ÊøÄ„Åó„ÅÑ', 'ÂãïÁöÑ', '„Ç®„Éç„É´„ÇÆ„ÉÉ„Ç∑„É•'], tone: 'dynamic' }
    ];

    for (const emotion of emotions) {
      if (emotion.keywords.some(keyword => summary.includes(keyword))) {
        return emotion.tone;
      }
    }

    return 'neutral';
  }

  /**
   * Generate story context from combined information
   */
  private generateStoryContext(
    caption: string,
    nearbyText: string,
    pageContext: string
  ): string {
    const contexts = [caption];
    
    if (nearbyText) {
      contexts.push(`Èñ¢ÈÄ£„ÉÜ„Ç≠„Çπ„Éà: ${nearbyText}`);
    }
    
    if (pageContext) {
      contexts.push(`„Éö„Éº„Ç∏ÊñáËÑà: ${pageContext}`);
    }

    return contexts.join(' | ');
  }

  /**
   * Calculate confidence from API response
   */
  private calculateConfidenceFromResponse(response: any): number {
    // Vertex AI doesn't always provide confidence scores
    // We'll use a heuristic based on response quality
    const text = response.response?.candidates?.[0]?.content?.parts?.map((p: any) => p.text).join("") ?? "";
    
    if (!text) return 0;
    if (text.length < 20) return 0.3;
    if (text.length < 50) return 0.6;
    if (text.length < 100) return 0.8;
    return 0.9;
  }
}

// Type definitions
export type CaptionStyle = "narrative" | "detailed" | "technical" | "emotional";

export interface CaptionResult {
  caption: string;
  confidence: number;
  style?: CaptionStyle;
  timestamp?: string;
  error?: string;
}

export interface ImageAnalysisResult {
  answers: Record<string, string>;
  summary: string;
  confidence: number;
  timestamp?: string;
  error?: string;
}

export interface EnhancedCaptionResult {
  caption: string;
  analysis: Record<string, string>;
  visualElements: string[];
  emotionalTone: string;
  storyContext: string;
  confidence: number;
  imageIndex: number;
  error?: string;
}

// Singleton instance
export const imageCaptioningService = new ImageCaptioningService();